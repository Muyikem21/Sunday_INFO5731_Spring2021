{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muyikem21/Sunday_INFO5731_Spring2021/blob/main/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4PFGWfFRA0o"
      },
      "source": [
        "## The third In-class-exercise (9/16/2020, 20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKmzbz1zRA00"
      },
      "source": [
        "The purpose of this exercise is to under users' information needs, then collect the data for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywBxy3NnRA01"
      },
      "source": [
        "Question 1 (8 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiERfG2yRA02"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Have you ever wondered how media platforms, and others recommend you what to watch next? To do so, they use a tool called\n",
        "the recommender/recommendation system. It takes several metrics into consideration, such as age, previously watched shows, \n",
        "most-watched genre, watch frequency, and feeds them into a Machine Learning model which then generates what the user might \n",
        "like to watch next. Based on my preference data, I can build either a content-based recommendation system or a collaborative\n",
        "filtering recommendation system. I will need 58,000 movies for the project. To obtain this data, I will use SP500 Index \n",
        "components, whose list is readily available online at the relevant Wikipedia page, and then save the dataset into csv file.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HAZu-2iRA02"
      },
      "source": [
        "Question 2 (12 points): Write python code to collect 500 items of the data you plan to collect above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXMfIGn-RA03"
      },
      "source": [
        "# Import relevant Packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "url=\"www.fastquicksearch.com/Movies Movies/Here\"\n",
        "\n",
        "#Scrape data\n",
        "r = requests.get(url,timeout=2.5)\n",
        "r_www = r.text\n",
        "soup = BeautifulSoup(r_www, 'www.parser')\n",
        "components_table = soup.find_all(id=\"constituents\")\n",
        "headers_www = soup.find_all(\"movies\")\n",
        "df_columns=[item.text.rstrip(\"\\n\") for item in headers_www]\n",
        "\n",
        "#Store data into a Pandas Dataframe\n",
        "components_headers=df_columns[:10]\n",
        "data_rows=components_table[0].find(\"movies\").find_all(\"movies\")[1:]\n",
        "rows=[]\n",
        "for row in range(len(data_rows))\n",
        "Mov=list(filter(None,data_rows[row].text.split(\"\\n\")))\n",
        "rows.append(Mov)\n",
        "\n",
        "# Save dataset into csv file\n",
        "S_P_500_movies=pd.DataFrame(rows,columns=components_headers)\n",
        "S_P_500_movies.drop(\"SEC filings\",inplace=True,axis=1)\n",
        "S_P_500_Mov.to_csv(r\"/home/edo_romani1/my-python-directory/SP500Mov.csv\",index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}