{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muyikem21/Sunday_INFO5731_Spring2021/blob/main/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMC61-CIqFhT"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 4/16/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egT6wiuAqFhm"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDzgtmiXqFhn"
      },
      "source": [
        "#libraries\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "\n",
        "#Data preperation\n",
        "\n",
        "testdata = open('stsa-test.txt', 'r')\n",
        "testdata.close()        \n",
        "              \n",
        "trainingdata =  open('stsa-train.txt', 'r')\n",
        "trainingdata.close()\n",
        "\n",
        "X = trainingdata\n",
        "y = testdata\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "#xgboost\n",
        "\n",
        "parameter = {\n",
        "            'objective':'binary:logistic',\n",
        "            'max_depth': 2,\n",
        "            'alpha': 10,\n",
        "            'learning_rate': 1.0,\n",
        "            'n_estimators':10}\n",
        "\n",
        "# instantiate the classifier \n",
        "model= XGBClassifier(**parameter)\n",
        "\n",
        "# fit the classifier to the training data\n",
        "model.fit(X,y)\n",
        "\n",
        "#random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Multinominal NB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X, y)\n",
        "\n",
        "# SVM\n",
        "\n",
        "cmodel=svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "model.score(X_test, y_test)\n",
        "\n",
        "# KNN\n",
        "\n",
        "# Create KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "# Fit the classifier to the data\n",
        "knn.fit(X_train,y_train)\n",
        "\n",
        "# Decision tree\n",
        "\n",
        "model = tree.DecisionTreeClassifier()\n",
        "model = model.fit(X, y)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}